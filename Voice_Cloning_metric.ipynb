{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljta8hPt1chs"
      },
      "outputs": [],
      "source": [
        "#prep\n",
        "import os\n",
        "!pip install tqdm -q\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "from os.path import exists, join, basename, splitext\n",
        "!pip install resampy\n",
        "!pip install git+https://github.com/IAHispano/gdown.git\n",
        "git_repo_url = 'https://github.com/justinjohn0306/TTS-TT2.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "# clone and install\n",
        "  !git clone -q --recursive {git_repo_url}\n",
        "  !git clone -q --recursive https://github.com/justinjohn0306/hifi-gan\n",
        "  !pip install -q unidecode\n",
        "import sys\n",
        "sys.path.append('hifi-gan')\n",
        "sys.path.append(project_name)\n",
        "\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "logging.getLogger('librosa').setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "#Universal HiFi-GAN (has some robotic noise): 1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown **The \"tacotron_id\" is where you can put a link to your trained tacotron2 model from Google Drive.**\n",
        "\n",
        "\n",
        "#@markdown If the audio sounds too artificial, you can lower the superres_strength\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Config:\n",
        "\n",
        "#@markdown Restart the runtime to apply any changes.\n",
        "\n",
        "tacotron_id = \"1IElD24WJEiiY5GO4LMJTQJWtGjmo_qfb\" #@param {type:\"string\"}\n",
        "\n",
        "hifigan_id = \"1-JWgMJ0RS__dBhdpjscxwe4xJ7_mA0HK\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown _leave blank or enter \"universal\" for universal model_\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "if tacotron_id != \"\":\n",
        "    TACOTRON2_ID = tacotron_id\n",
        "else:\n",
        "    raise Exception(\"No ID provided.\")\n",
        "\n",
        "if hifigan_id in {\"\", \"universal\"}:\n",
        "    HIFIGAN_ID = \"universal\"\n",
        "    print(\"Using universal Hifi-Gan model.\")\n",
        "else:\n",
        "    HIFIGAN_ID = hifigan_id\n",
        "\n",
        "# Check if Initialized\n",
        "try:\n",
        "    initialized\n",
        "except NameError:\n",
        "    print(\"Setting up, please wait.\\n\")\n",
        "    with tqdm(total=5, leave=False) as pbar:\n",
        "\n",
        "        import time\n",
        "        import matplotlib\n",
        "        import matplotlib.pylab as plt\n",
        "        import gdown\n",
        "        d = 'https://drive.google.com/uc?id='\n",
        "\n",
        "        %matplotlib inline\n",
        "        import IPython.display as ipd\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        import json\n",
        "        from hparams import create_hparams\n",
        "        from model import Tacotron2\n",
        "        from layers import TacotronSTFT\n",
        "        from audio_processing import griffin_lim\n",
        "        from text import text_to_sequence\n",
        "        from env import AttrDict\n",
        "        from meldataset import mel_spectrogram, MAX_WAV_VALUE\n",
        "        from models import Generator\n",
        "        from denoiser import Denoiser\n",
        "        import resampy\n",
        "        import scipy.signal\n",
        "\n",
        "        pbar.update(1) # initialized Dependancies\n",
        "\n",
        "        graph_width = 900\n",
        "        graph_height = 360\n",
        "        def plot_data(data, figsize=(int(graph_width/100), int(graph_height/100))):\n",
        "            %matplotlib inline\n",
        "            fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "            for i in range(len(data)):\n",
        "                axes[i].imshow(data[i], aspect='auto', origin='lower',\n",
        "                            interpolation='none', cmap='inferno')\n",
        "            fig.canvas.draw()\n",
        "            plt.show()\n",
        "\n",
        "        # Setup Pronounciation Dictionary\n",
        "        !wget 'https://github.com/justinjohn0306/FakeYou-Tacotron2-Notebook/releases/download/CMU_dict/merged.dict.txt'\n",
        "        thisdict = {}\n",
        "        for line in reversed((open('merged.dict.txt', \"r\").read()).splitlines()):\n",
        "            thisdict[(line.split(\" \",1))[0]] = (line.split(\" \",1))[1].strip()\n",
        "\n",
        "        pbar.update(1) # Downloaded and Set up Pronounciation Dictionary\n",
        "\n",
        "        def ARPA(text, punctuation=r\"!?,.;\", EOS_Token=True):\n",
        "            out = ''\n",
        "            for word_ in text.split(\" \"):\n",
        "                word=word_; end_chars = ''\n",
        "                while any(elem in word for elem in punctuation) and len(word) > 1:\n",
        "                    if word[-1] in punctuation: end_chars = word[-1] + end_chars; word = word[:-1]\n",
        "                    else: break\n",
        "                try:\n",
        "                    word_arpa = thisdict[word.upper()]\n",
        "                    word = \"{\" + str(word_arpa) + \"}\"\n",
        "                except KeyError: pass\n",
        "                out = (out + \" \" + word + end_chars).strip()\n",
        "            if EOS_Token and out[-1] != \";\": out += \";\"\n",
        "            return out\n",
        "\n",
        "        def get_hifigan(MODEL_ID, conf_name):\n",
        "            # Download HiFi-GAN\n",
        "            hifigan_pretrained_model = 'hifimodel_' + conf_name\n",
        "            #gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "            if MODEL_ID == 1:\n",
        "              !wget \"https://github.com/justinjohn0306/tacotron2/releases/download/assets/Superres_Twilight_33000\" -O $hifigan_pretrained_model\n",
        "            elif MODEL_ID == \"universal\":\n",
        "              !wget \"https://github.com/justinjohn0306/tacotron2/releases/download/assets/g_02500000\" -O $hifigan_pretrained_model\n",
        "            else:\n",
        "              gdown.download(d+MODEL_ID, hifigan_pretrained_model, quiet=False)\n",
        "\n",
        "            if not exists(hifigan_pretrained_model):\n",
        "                raise Exception(\"HiFI-GAN model failed to download!\")\n",
        "\n",
        "            # Load HiFi-GAN\n",
        "            conf = os.path.join(\"hifi-gan\", conf_name + \".json\")\n",
        "            with open(conf) as f:\n",
        "                json_config = json.loads(f.read())\n",
        "            h = AttrDict(json_config)\n",
        "            torch.manual_seed(h.seed)\n",
        "            hifigan = Generator(h).to(torch.device(\"cpu\"))\n",
        "            state_dict_g = torch.load(hifigan_pretrained_model, map_location=torch.device(\"cpu\"))\n",
        "            hifigan.load_state_dict(state_dict_g[\"generator\"])\n",
        "            hifigan.eval()\n",
        "            hifigan.remove_weight_norm()\n",
        "            denoiser = Denoiser(hifigan, mode=\"normal\")\n",
        "            return hifigan, h, denoiser\n",
        "\n",
        "        # Download character HiFi-GAN\n",
        "        hifigan, h, denoiser = get_hifigan(HIFIGAN_ID, \"config_v1\")\n",
        "        # Download super-resolution HiFi-GAN\n",
        "        hifigan_sr, h2, denoiser_sr = get_hifigan(1, \"config_32k\")\n",
        "        pbar.update(1) # Downloaded and Set up HiFi-GAN\n",
        "\n",
        "        def has_MMI(STATE_DICT):\n",
        "            return any(True for x in STATE_DICT.keys() if \"mi.\" in x)\n",
        "\n",
        "        def get_Tactron2(MODEL_ID):\n",
        "            # Download Tacotron2\n",
        "            tacotron2_pretrained_model = 'MLPTTS'\n",
        "            gdown.download(d+MODEL_ID, tacotron2_pretrained_model, quiet=False)\n",
        "            if not exists(tacotron2_pretrained_model):\n",
        "                raise Exception(\"Tacotron2 model failed to download!\")\n",
        "            # Load Tacotron2 and Config\n",
        "            hparams = create_hparams()\n",
        "            hparams.sampling_rate = 22050\n",
        "            hparams.max_decoder_steps = 3000 # Max Duration\n",
        "            hparams.gate_threshold = 0.25 # Model must be 25% sure the clip is over before ending generation\n",
        "            model = Tacotron2(hparams)\n",
        "            state_dict = torch.load(tacotron2_pretrained_model, map_location=torch.device(\"cpu\"))['state_dict']\n",
        "            if has_MMI(state_dict):\n",
        "                raise Exception(\"ERROR: This notebook does not currently support MMI models.\")\n",
        "            model.load_state_dict(state_dict)\n",
        "            _ = model.eval()\n",
        "            return model, hparams\n",
        "\n",
        "        model, hparams = get_Tactron2(TACOTRON2_ID)\n",
        "        previous_tt2_id = TACOTRON2_ID\n",
        "\n",
        "        pbar.update(1) # Downloaded and Set up Tacotron2\n",
        "\n",
        "        # Extra Info\n",
        "        def end_to_end_infer(text, pronounciation_dictionary, show_graphs):\n",
        "            for i in [x for x in text.split(\"\\n\") if len(x)]:\n",
        "                if not pronounciation_dictionary:\n",
        "                    if i[-1] != \";\": i=i+\";\"\n",
        "                else: i = ARPA(i)\n",
        "                with torch.no_grad(): # save VRAM by not including gradients\n",
        "                    sequence = np.array(text_to_sequence(i, ['english_cleaners']))[None, :]\n",
        "                    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).long()\n",
        "                    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "                    if show_graphs:\n",
        "                        plot_data((mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "                                alignments.float().data.cpu().numpy()[0].T))\n",
        "                    y_g_hat = hifigan(mel_outputs_postnet.float())\n",
        "                    audio = y_g_hat.squeeze()\n",
        "                    audio = audio * MAX_WAV_VALUE\n",
        "                    audio_denoised = denoiser(audio.view(1, -1), strength=35)[:, 0]\n",
        "\n",
        "                    # Resample to 32k\n",
        "                    audio_denoised = audio_denoised.cpu().numpy().reshape(-1)\n",
        "\n",
        "                    normalize = (MAX_WAV_VALUE / np.max(np.abs(audio_denoised))) ** 0.9\n",
        "                    audio_denoised = audio_denoised * normalize\n",
        "                    wave = resampy.resample(\n",
        "                        audio_denoised,\n",
        "                        h.sampling_rate,\n",
        "                        h2.sampling_rate,\n",
        "                        filter=\"sinc_window\",\n",
        "                        window=scipy.signal.windows.hann,\n",
        "                        num_zeros=8,\n",
        "                    )\n",
        "                    wave_out = wave.astype(np.int16)\n",
        "\n",
        "                    # HiFi-GAN super-resolution\n",
        "                    wave = wave / MAX_WAV_VALUE\n",
        "                    wave = torch.FloatTensor(wave).to(torch.device(\"cpu\"))\n",
        "                    new_mel = mel_spectrogram(\n",
        "                        wave.unsqueeze(0),\n",
        "                        h2.n_fft,\n",
        "                        h2.num_mels,\n",
        "                        h2.sampling_rate,\n",
        "                        h2.hop_size,\n",
        "                        h2.win_size,\n",
        "                        h2.fmin,\n",
        "                        h2.fmax,\n",
        "                    )\n",
        "                    y_g_hat2 = hifigan_sr(new_mel)\n",
        "                    audio2 = y_g_hat2.squeeze()\n",
        "                    audio2 = audio2 * MAX_WAV_VALUE\n",
        "                    audio2_denoised = denoiser(audio2.view(1, -1), strength=35)[:, 0]\n",
        "\n",
        "                    # High-pass filter, mixing and denormalizing\n",
        "                    audio2_denoised = audio2_denoised.cpu().numpy().reshape(-1)\n",
        "                    b = scipy.signal.firwin(\n",
        "                        101, cutoff=10500, fs=h2.sampling_rate, pass_zero=False\n",
        "                    )\n",
        "                    y = scipy.signal.lfilter(b, [1.0], audio2_denoised)\n",
        "                    y *= superres_strength\n",
        "                    y_out = y.astype(np.int16)\n",
        "                    y_padded = np.zeros(wave_out.shape)\n",
        "                    y_padded[: y_out.shape[0]] = y_out\n",
        "                    sr_mix = wave_out + y_padded\n",
        "                    sr_mix = sr_mix / normalize\n",
        "\n",
        "                    print(\"\")\n",
        "                    ipd.display(ipd.Audio(sr_mix.astype(np.int16), rate=h2.sampling_rate))\n",
        "    from IPython.display import clear_output\n",
        "    clear_output()\n",
        "    initialized = \"Ready\"\n",
        "\n",
        "if previous_tt2_id != TACOTRON2_ID:\n",
        "    print(\"Updating Models\")\n",
        "    model, hparams = get_Tactron2(TACOTRON2_ID)\n",
        "    hifigan, h, denoiser = get_hifigan(HIFIGAN_ID, \"config_v1\")\n",
        "    previous_tt2_id = TACOTRON2_ID\n",
        "\n",
        "pronounciation_dictionary = False #@param {type:\"boolean\"}\n",
        "# disables automatic ARPAbet conversion, useful for inputting your own ARPAbet pronounciations or just for testing\n",
        "show_graphs = False #@param {type:\"boolean\"}\n",
        "max_duration =  10#@param {type:\"integer\"}\n",
        "model.decoder.max_decoder_steps = max_duration * 80\n",
        "stop_threshold = 0.3 #@param {type:\"number\"}\n",
        "model.decoder.gate_threshold = stop_threshold\n",
        "superres_strength = 6 #@param {type:\"number\"}\n",
        "\n",
        "print(f\"Current Config:\\npronounciation_dictionary: {pronounciation_dictionary}\\nshow_graphs: {show_graphs}\\nmax_duration (in seconds): {max_duration}\\nstop_threshold: {stop_threshold}\\nsuperres_strength: {superres_strength}\\n\\n\")\n",
        "\n",
        "time.sleep(1)\n",
        "contents = []\n",
        "# Define the data (use your complete input as needed)\n",
        "data = \"\"\"wavs/clip_slide3_0000-0010.wav|Let's see some examples. So first, right is above the domain adaptation. So in this slide, we will see our\n",
        "wavs/clip_slide3_0070-0080.wav|We have another kind of datasets in the medical field. For example, we have the t one images and we have the flare images if we\n",
        "wavs/clip_slide4_0000-0010.wav|And I will introduce one more of the previous that I developed out of those examples. That's exactly how manifold\n",
        "wavs/clip_slide5_0030-0040.wav|In this case, it's just a 16. And there's a out is the outer is just about, you know, 1, the shape of your brain structure.\n",
        "wavs/clip_slide7_0020-0030.wav|Different causes of the diseases. If it is one, it means normal. If it is two, it means it's abnormal. So sometimes you\n",
        "wavs/clip_slide9_0010-0020.wav|Left hand, you see a lot of, like, noise. You just, you know, bring it over. But on your right hand, once you get the denoised,\n",
        "wavs/clip_slide10_0010-0020.wav|Here. Right? And the same on the left hand, the this figure is about noisy mixing birds. By the right hand, there are 2 different colors. So\n",
        "wavs/clip_slide11_0040-0042.wav|And there's this one is a very pretty big.\n",
        "wavs/clip_slide13_0030-0039.wav|And then this here is just our Canvas page, and then you can feel free to have some discussions online.\n",
        "wavs/clip_slide15_0030-0034.wav|In the office after any kind of questions. Okay?\n",
        "wavs/clip_slide18_0040-0050.wav|It's about thirty percentage for that reason, your final project is like your first semester first year come to my office, talk to me to\n",
        "wavs/clip_slide18_0130-0140.wav|Yes. We, depending on your guys. If you guys sound like, other at the most, I would like to say two students per group.\n",
        "wavs/clip_slide20_0010-0020.wav|And data pre processing in the 3rd way, we are talking about the classification after that, we will talk about some regression and list\n",
        "wavs/clip_slide20_0060-0070.wav|We have, like, neural network, Anselm method, and we are finished about the horse method, I'll have to emphasize that soon.\n",
        "wavs/clip_slide20_0130-0140.wav|The final project, professor. Yes. Let's go try to find it in our syllabus again. So here's all the content that I will cover.\n",
        "wavs/clip_slide20_0160-0170.wav|Are all the projects independent for that or, like, a teamwork professor? You mean the homework student wanna know the project project?\n",
        "wavs/clip_slide20_0220-0230.wav|In your interview, how you will implement the scale? These kinds of algorithms like Gaussian Mixture Model, how you will implement?\n",
        "wavs/clip_slide20_0250-0260.wav|Immediately implemented, and you definitely have a good impression of them. So now the, might need some might hire you immediately, hopefully. Okay.\n",
        "wavs/clip_slide22_0040-0050.wav|What about the other source? This is so yeah. It's still kinda often. What about the other source of of from online students?\n",
        "wavs/clip_slide24_0000-0010.wav|So first of all, was the perception of we also say it as, representation so in AI, perception\n",
        "wavs/clip_slide25_0000-0010.wav|But what about learning? So the learning is the ability of a system to improve its behavior based on experience. So\n",
        "wavs/clip_slide27_0020-0030.wav|Level and applying it at other level, so then another question, so among those four different aspects, Which\n",
        "wavs/clip_slide27_0080-0082.wav|Answer.\n",
        "wavs/clip_slide29_0030-0040.wav|Verification and validation is more like you like your phone.\n",
        "wavs/clip_slide29_0100-0110.wav|Especially the amount that data labeling is a big challenge for all existing machine learning. For those, you definitely need to provide feed\n",
        "wavs/clip_slide29_0160-0170.wav|Interaction, the HCI and Israeli would like a little bit longer time than single computer models, but you know\n",
        "wavs/clip_slide30_0060-0070.wav|Label the input data. So then one features and labels, professor, feature and labels cn, that's yes. Exactly.\n",
        "wavs/clip_slide30_0130-0140.wav|You've got some stock price predictions, so the stock price on your level our levels of it, right, giving you\n",
        "wavs/clip_slide32_0020-0030.wav|Of that in the nineteen sixties, like the earliest offer network, it's called perception as it was born at that time.\n",
        "wavs/clip_slide33_0020-0028.wav|Finding some tasks and learning, some reinforcement learning and inductive logic programming, etcetera.\n",
        "wavs/clip_slide34_0030-0040.wav|About two years ago in the two thousand tens. In that, stage, and like, deep learning is rarely and becomes popular. Right?\n",
        "wavs/clip_slide37_0000-0010.wav|So this is about the intuition of showing how it handles themselves. Actually, there are no specific features that\n",
        "wavs/clip_slide37_0060-0070.wav|Yes. Right? What about the world? And that's about our children, so really humanness learn from experience.\n",
        "wavs/clip_slide38_0030-0040.wav|Model is bigger, professor. Yes. That's very good spectrum. What about some thoughts about you guys use tradition?\n",
        "wavs/clip_slide38_0100-0110.wav|Sum of if a statement and a check if that's related to a cat or not, professor. Good. You have a similar\n",
        "wavs/clip_slide39_0030-0040.wav|We want to detect the shape, we want to detect the length, and we have so many different if else statements. So finally to decide\n",
        "wavs/clip_slide41_0000-0010.wav|Very challenging. I mean, different shape. Strange shape somehow has a cat more like water. It can be in any shape. Right?\n",
        "wavs/clip_slide43_0000-0010.wav|So now we talk about the questions some what is machine learning? And this is very important The early stage of computer\n",
        "wavs/clip_slide44_0020-0030.wav|Because we are human beings. Right? And we are we were lazy. We don't we cannot do everything. We want some computers\n",
        "wavs/clip_slide46_0000-0010.wav|The next question is, why study machine learning? Why is it important? Here's the case in that we want to develop a better computer system.\n",
        "wavs/clip_slide46_0060-0070.wav|Users. For example, personalized news, the mailing filtering, for example, sometimes you have some app.\n",
        "wavs/clip_slide47_0010-0020.wav|Learn is not intelligent. So, actually, without learning, everything is new. Right? A system that cannot learn is not efficient because it\n",
        "wavs/clip_slide48_0000-0010.wav|You will try to use machine learning For example, in the speech recognition for example, you will use Siri and ask her to do\n",
        "wavs/clip_slide51_0000-0010.wav|And, also, we can recognize, handwritten digits. For example, this kind of very weird. Right? It's it is weird. Right?\n",
        "wavs/clip_slide54_0010-0017.wav|Been there before, right? Who can use some robot machine help us be explored first, right?\n",
        "wavs/clip_slide56_0000-0010.wav|Another trend is about why machine learning models are so popular. Right? Because, there are so many places that we needed to use machine learning\n",
        "wavs/clip_slide56_0090-0097.wav|To use machine learning, and this is the key reason why machine learning nowadays is so popular and important.\n",
        "wavs/clip_slide58_0020-0030.wav|Learning we have we will use labeled dataset, right, as the unsupervised learning just to discover patterns in unlabeled dataset.\n",
        "wavs/clip_slide59_0010-0020.wav|Had a semi supervised. Another count between those ones, As a majority, we have three those three different categories, for example, is\n",
        "wavs/clip_slide59_0050-0060.wav|Unlabeled data is a traditional sense is a reinforcement learning. An agent learns via its interactions with any environment.\n",
        "wavs/clip_slide60_0010-0020.wav|The perception, especially about logistic regression. I think all of you should know about from your first semester. Right?\n",
        "wavs/clip_slide60_0070-0080.wav|The non parametric models they just they need just that those models vary depending on dataset they don't care\n",
        "wavs/clip_slide60_0120-0128.wav|For majority of those kinds of methods, we will cover the rest of the semester, you will see about that.\n",
        "wavs/clip_slide62_0050-0060.wav|Predictor labels. Right? However, why important the process is called feature extraction? Well done.\n",
        "wavs/clip_slide62_0100-0110.wav|Method to extract some key features from data So here, it is the images. The key feature\n",
        "wavs/clip_slide62_0160-0163.wav|You will get more sense of it.\n",
        "wavs/clip_slide63_0040-0050.wav|Based on some clustering method. Right? For example, that like some knn k nearest neighbor, you will probably choose.\n",
        "wavs/clip_slide63_0090-0097.wav|Those two different classes, this is, cool called unsupervised learning.\n",
        "wavs/clip_slide64_0090-0100.wav|Anyway, you guys will learn more details that in the AI, artificial intelligence class, or reinforcement learning class, and specifically for\n",
        "wavs/clip_slide65_0010-0020.wav|We only utilize a kind of traditional machine learning models. For example, I like the decision tree, the SVM, the KAN, The MLP\n",
        "wavs/clip_slide66_0010-0020.wav|Works support vector machine and the symbolic functions, we have decision trees, processional logic, rules for the first\n",
        "wavs/clip_slide68_0000-0010.wav|For example, this is very about the medical diseases diagnosis is left for about this image. Any idea about this image?\n",
        "wavs/clip_slide69_0010-0020.wav|Your eyes, where is your nose? Where is your mouse? Right? It's funny areas. Right? It's really about personal identification. So\n",
        "wavs/clip_slide71_0010-0012.wav|just tries to shoot a posture.\n",
        "wavs/clip_slide76_0030-0040.wav|Right? And there's that's there's some repetitive tasks for some tasks that you will repeatedly do it so\n",
        "wavs/clip_slide77_0020-0028.wav|Example, like packaging, the first need is to recollect objects. So then you can package those objects.\n",
        "wavs/clip_slide82_0010-0018.wav|And also about military suits, or about this case try to do some detections, some problem of it.\n",
        "wavs/clip_slide84_0040-0050.wav|You do not want to break it, either to break, the object or to break the robot itself. What about this cleaner?\n",
        "wavs/clip_slide87_0000-0010.wav|And this is a famous sentence from Birgitte that a breakthrough in machine learning will be worth 10 Microsofts. Is that\n",
        "wavs/clip_slide89_0040-0050.wav|For example, you guys have such a lot of those questions, like machine learning, and then that's the key reason you guys need to start in this.\n",
        "wavs/clip_slide90_0040-0050.wav|Remind this class, I will require you guys also to provide some answers from chat gbt answers. Okay? So, basically, which means that\n",
        "wavs/clip_slide91_0000-0010.wav|So for example, here is the example from me from me. And since this is for the examples from the chat gpt, but the question, what is\n",
        "wavs/clip_slide91_0070-0080.wav|Well, you cannot beat a machine. Right? You cannot beat the a chat gbt with a good answer. Right? Try to avoid that. Okay. Others probably\n",
        "wavs/slide31.wav|So next, I want to briefly mention about the history of the Machine Learning.\n",
        "wavs/slide83.wav|And also, you know about the space robot that I mentioned before to try to explore the Mars. Right?\"\"\"\n",
        "\n",
        "# Split the input data by lines\n",
        "lines = data.strip().split('\\n')\n",
        "\n",
        "# Extract the text part (after the '|')\n",
        "sentences = [line.split('|')[1] for line in lines]\n",
        "\n",
        "for i in sentences:\n",
        "    try:\n",
        "        print(\"-\"*50)\n",
        "        line = i\n",
        "        if line == \"\":\n",
        "            continue\n",
        "        end_to_end_infer(line, not pronounciation_dictionary, show_graphs)\n",
        "    except EOFError:\n",
        "        break\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Stopping...\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MLmJ2bM-1ch1",
        "outputId": "9c1e0e6c-0d86-4c7f-9666-352a5926f552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['1.wav', '2.wav', '3.wav', '4.wav', '5.wav', '6.wav', '7.wav', '8.wav', '9.wav', '10.wav', '11.wav', '12.wav', '13.wav', '14.wav', '15.wav', '16.wav', '17.wav', '18.wav', '19.wav', '20.wav', '21.wav', '22.wav', '23.wav', '24.wav', '25.wav', '26.wav', '27.wav', '28.wav', '29.wav', '30.wav', '31.wav', '32.wav', '33.wav', '34.wav', '35.wav', '36.wav', '37.wav', '38.wav', '39.wav', '40.wav', '41.wav', '42.wav', '43.wav', '44.wav', '45.wav', '46.wav', '47.wav', '48.wav', '49.wav', '50.wav', '51.wav', '52.wav', '53.wav', '54.wav', '55.wav', '56.wav', '57.wav', '58.wav', '59.wav', '60.wav', '61.wav', '62.wav', '63.wav', '64.wav', '65.wav', '66.wav', '67.wav', '68.wav', '69.wav', '70.wav', '71.wav', '72.wav', '73.wav', '74.wav', '75.wav', '76.wav', '77.wav', '78.wav', '79.wav', '80.wav', '81.wav', '82.wav', '83.wav', '84.wav', '85.wav', '86.wav', '87.wav', '88.wav', '89.wav', '90.wav', '91.wav', '92.wav', '93.wav', '94.wav', '95.wav', '96.wav', '97.wav', '98.wav', '99.wav', '100.wav', '101.wav', '102.wav', '103.wav', '104.wav', '105.wav', '106.wav', '107.wav', '108.wav', '109.wav', '110.wav', '111.wav', '112.wav', '113.wav', '114.wav', '115.wav', '116.wav', '117.wav', '118.wav', '119.wav', '120.wav', '121.wav', '122.wav', '123.wav', '124.wav', '125.wav', '126.wav', '127.wav', '128.wav', '129.wav', '130.wav', '131.wav', '132.wav', '133.wav', '134.wav', '135.wav', '137.wav', '138.wav', '139.wav', '140.wav', '141.wav', '142.wav', '143.wav', '144.wav', '145.wav', '146.wav', '147.wav', '148.wav', '149.wav', '150.wav', '151.wav', '152.wav', '153.wav', '154.wav', '155.wav', '156.wav', '157.wav', '158.wav', '159.wav', '160.wav', '161.wav', '162.wav', '163.wav', '164.wav', '165.wav', '166.wav', '167.wav', '168.wav', '169.wav', '170.wav', '171.wav', '172.wav', '173.wav', '174.wav', '175.wav', '176.wav', '177.wav', '178.wav', '179.wav', '180.wav', '181.wav', '182.wav', '183.wav', '184.wav', '185.wav', '186.wav', '187.wav', '188.wav', '189.wav', '190.wav', '191.wav', '192.wav', '193.wav', '194.wav', '195.wav', '196.wav', '197.wav', '198.wav', '199.wav', '200.wav', '201.wav', '202.wav', '203.wav', '204.wav', '205.wav', '206.wav', '207.wav', '208.wav', '209.wav']\n",
            "Average PESQ score: 1.5692185163497925\n",
            "Average STOI score: 0.23134693503379822\n",
            "Average csig score: 2.5521769523620605\n",
            "Average cbak score: 1.667487382888794\n",
            "Average covl score: 1.9533746242523193\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from torchmetrics.audio.pesq import PerceptualEvaluationSpeechQuality\n",
        "from torchmetrics.audio.stoi import ShortTimeObjectiveIntelligibility\n",
        "import pysepm\n",
        "from pesq import pesq\n",
        "from pystoi import stoi\n",
        "from scipy.io import wavfile\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "# Initialize PESQ and STOI with 16kHz sample rate\n",
        "pesq = PerceptualEvaluationSpeechQuality(16000, 'wb')\n",
        "stoi = ShortTimeObjectiveIntelligibility(16000)\n",
        "\n",
        "\n",
        "# Data to process\n",
        "data = \"\"\"wavs/1.wav|AKAN GRAVES TODAY HER GRANDDAUGHTER STEPHANI SERVES AS A GUIDE AT THIS CEMETERY THIS WEEK\n",
        "wavs/2.wav|E DAVID ARRAYED ON THESE BEAUTIFUL GROUNDS EACH ONE HAS BEEN ADOPTED BY A FRENCH FAMILY THAT THINKS\n",
        "wavs/3.wav|PLAYS FLOWERS AND THEY NEVER FORGET TO DAY AMERICA EMBRACES THE FRENCH PEOPLE AND THANKS YOU FOR\n",
        "wavs/4.wav|IS  UNBREAKABLE FROM ACROSS THE EARTH AMERICANS ARE DRAWN TO THIS PLACE AS THOUGH IT WERE A PART OF OUR VERY SOUL WE\n",
        "wavs/5.wav|CUM NOT ONLY BECAUSE OF WHATT THEY DID HEAR WE COME BECAUSE OF WHO THEY WERE THEY WERE YOUNG MEN\n",
        "wavs/6.wav|WITH THEIR ENTIRE LIVES BEFORE THEM THEY WERE HUSBANDS WHO SAID GOOD BY TO THEIR YOUNG BRIDES AND TOOK THEIR DUTY AS\n",
        "wavs/7.wav|THEIR FATE THEY WERE FATHERS WHO WOULD NEVER MEET THEIR INFINITE SONS AND DAUGHTERS BECAUSE THEY HAD A JOB TO DO AND WITH GOD AS THEIR WITNESS\n",
        "wavs/8.wav|THOUT A COMPLAINT MORE POWERFUL THAN THE STRENGTH OF AMERICAN ARMS WAS THE STRENGTH OF AMERICAN HORACE\n",
        "wavs/9.wav|THEY PRESSED ON FOR LOVE AND HOME AND COUNTRY THE MAIN STREETS THE SCHOOLYARDS THE CHURCHES AND NEIGHBOURS THE FAMILIES AND COMMUNITIE\n",
        "wavs/10.wav|THEY GAVE US MEN SUCH AS THESE THEY WERE SUSTAINED BY THE CONFIDENCE THAT AMERICA CAN DO ANYTHING BECAUSE WE ARE A NOBLE NATIO\n",
        "wavs/11.wav|OF GOD'S HAND THE MEN BEHIND ME WILL TELL YOU THAT THEY ARE JUST THE LUCKY ONES AS\n",
        "wavs/12.wav|S ONE OF THEM RECENTLY BEHOODED ALL THE HEROES ARE BURIED HERE BUT WE KNOW WHAT THESE MEN DID\n",
        "wavs/13.wav|WHAT FREEDOMM IS ALL ABOUT THE AMERICAN SONS AND DAUGHTERS WHO SAW US TO VICTORY WERE NO LESS EXTRAORDINAR\n",
        "wavs/14.wav|REVOLUTIONIZED SCIENCE LAUNCHED A MAN TO THE MOON AND THEN KEPT ON PUSHING TO NEW FRONTIERS\n",
        "wavs/15.wav|HERE WITH YOU ARE OVER SIXTY VETERANS WHO LANDED ON D DAY OUR DEBT TO YOU IS EVERLASTING TO DAY WE EXPRESS OUR UNDYING\n",
        "wavs/16.wav|HO SPOKE OF A THOUSAND YEAR EMPIRE IN DEFEATING THAT EVIL THEY LEFT A LEGACY THAT WILL LAST NOT ONLY FOR A THOUSAND YEARS\n",
        "wavs/17.wav|THE BLOOD THAT THEY SPILLED THE TEARS THAT THEY SHED THE LIVES THAT THEY GAVE THE SACRIFICE THAT THE\n",
        "wavs/18.wav|OR NATION THEY WON THE SURVIVAL OF OUR CIVILIZATION AND THEY SHOWED US THE WAY TO LOVE CHERI\n",
        "wavs/19.wav|GRATITUDE WHEN YOU WERE YOUNG THESE MEN ENLISTED THEIR LIVES IN A GREAT CRUSADE ONE OF THE GREATEST OF ALL TIMES THEI\n",
        "wavs/20.wav|AND DEFEND OUR WAY OF LIFE FOR MANY CENTURIES TO COME TO DAY AS WE STAND TOGETHER UPON THIS SAINT CRITIC\n",
        "wavs/21.wav|EARTH WE PLEDGE THAT OUR NATION WILL FOREVER BE STRONG AND UNITED WE WILL FOREVER B\n",
        "wavs/22.wav|MISSION IS THE STORY OF AN EPOC BATTLE AND THE FEROCIOUS ETERNAL STRUGGLE BETWEEN GOOD AND EVIL ON THE SIXTH OF JUNE NINETEEN FORTY FOUR\n",
        "wavs/23.wav|THEY JOINED A LIBERATION FORCE OF AWESOME POWER AND BREATH TAKING SCALE AFTER MONTHS OF PLANTING THE ALLIES HAD CHOSEN THIS ANCIENT CO\n",
        "wavs/24.wav|ST LINE TO MOUNT THEIR CAMPAIGN TO VANQUISH THE WICKED TYRANNY OF THE NAZSI EMPIRE FROM THE FACE OF THE EARTH THE BATTLE B\n",
        "wavs/25.wav|AGAIN IN THE SKIES ABOVE US IN THOSE FIRST TENS MIDNIGHT HOURS ONE THOUSAND AIRCRAFT ROARED OVERHEAD WITH SEVENTEEN THOUSAND ALL\n",
        "wavs/26.wav|EYED AERBORN TROOPS PREPARING TO LEAP INTO THE DARKNESS BEYOND THESE TREES THEN CAME DAWN THE ENEMY WHO HAD OCCUPIED THESE HEIGHTS\n",
        "wavs/27.wav|SAW THE LARGEST NAVAL ARMADA IN THE HISTORY OF THE WORLD JUST A FEW MILES OFF SHORE WERE SEVEN THOUSAND VESSELS BEARING ONE\n",
        "wavs/28.wav|SSUS MACCROWN AND THE PEOPLE OF FRANCE TO THE FIRST LADY OF THE UNITED STATES AND MEMBERS OF THE UNI\n",
        "wavs/29.wav|HUNDRED AND THIRTY THOUSAND WARRIORS THEY WERE THE CITIZENS OF FREE AND INDEPENDENT NATIONS UNITED BY THEIR DUTY TO THEIR COMPATRIOTS\n",
        "wavs/30.wav|INTO MILLIONS YET UNBORN THERE WERE THE BRITISH WHOSE NOBILITY AND FORTITUDE SAW THEM THROUGH THE WORST OF\n",
        "wavs/31.wav|UNKIRK AND THE LONDON BLITS THE FULL VIOLENCE OF NAUNSEY FURY WAS NO MATCH FOR THE FULL GRANDEUR OF\n",
        "wavs/32.wav|THERE WERE THE CANADIANS WHOSE ROBUST SENSE OF HONOUR AND LOYALTY COMPEL THEM TO TAKE UP ARMS ALONGSIDE BRITAIN COM THE VERY VERY BEGINNING\n",
        "wavs/33.wav|THERE WERE THE FIGHTING POLES THE TOUGH NORWEGIANS AND THE INTREPID AUSES THERE WERE THE GALLANT FRENCH\n",
        "wavs/34.wav|MANDAS SOON TO BE MET BY THOUSANDS OF THEIR BRAVE COUNTRYMEN READY TO WRITE A NEW CHAPTER IN THE LONG HISTORY OF FRENCH VALOR\n",
        "wavs/35.wav|AMERICANS THEY CAME FROM THE FARMS OF A VAST HEARTLAND THE STREETS OF GLOWING CITIES AND THE FORGES OF MIGHTY\n",
        "wavs/36.wav|INDUSTRIAL TOWNS BEFORE THE WAR MANY HAD NEVER VENTURED BEYOND THEIR OWN COMMUNITY NOW THEY HAD COME TO OFFER THEIR LIVES\n",
        "wavs/37.wav|TED STATES CONGRESS TO DISTINGUISH GASSS VETERANS AND MY FELLOW AMERICANS WE ARE GATHERED HERE\n",
        "wavs/38.wav|HALF A WORLD FROM HOME THIS BEACH CODE NAMED OMAHA WAS DEFENDED BY THE N\n",
        "wavs/39.wav|ATSIUS WITH MONSTROUS FIRE POWER THOUSANDS AND THOUSANDS OF MINES AND SPIKES DRIVEN INTO THE SAND SO DEEPLY\n",
        "wavs/40.wav|IT WAS HERE THAT TENS OF THOUSANDS OF THE AMERICANS CAME THE GIIS WHO BOARDED THE LANDING CRAFT THAT MORNING KNEW THAT THEY C\n",
        "wavs/41.wav|CARRIED ON THEIR SHOULDERS NOT JUST THE PACK OF A SOLDIER BUT THE FATE OF THE WORLD COLONEL GEORGE TAYLOR WHO\n",
        "wavs/42.wav|SIXTEENTH INFANTRY REGIMENT WOULD JOIN IN THE FIRST WAIF WAS ASKED WHAT WOULD HAPPEN IF THE GERMAN STOPPED RIGHT\n",
        "wavs/43.wav|HEN AND THERE COLD ON THE BEACH JUST STOP TEM WHAT WOULD HAPPEN THIS GREAT AMERICAN REPLIED WHY THE EIGHTEENTH INFANNTRY IS COMING IN RIGHT BE\n",
        "wavs/44.wav|HIND US THE TWENTY SIXTH INFANTRY WILL COME ON TO THEN THERE IS THE SECOND INFANTRY DIVISION ALREADY AFLOAT A\n",
        "wavs/45.wav|THE NINTH DIVISION AND THE SECOND ARMOURED AND THE THIRD ARMOURED AND ALL THE REST MAYBE THE SIXTEENTH WON'T MAKE IT BUT SOMEONE WILL ONE OF\n",
        "wavs/46.wav|THOSE MEN IN TAILOR'S SIXTEENTH REGIMENT WAS ARMY METTICK RAY LAMBERT RAY WAS ONLY TWENTY THREE BUT HE HAD ALREADY EARN\n",
        "wavs/47.wav|THREE PURPLE HEARTS AND TWO SILVER STARS FIGHTING IN NORTH AFRICA AND SICILY WHERE HE AND HIS BROTHER BILL NO LONGER WITH US SERVED SIDE BY\n",
        "wavs/48.wav|ON FRIEDAM'S ALTAR ON THESE SHORES ON THESE BLUFFS ON THIS DAY SEVENTY FIVE YEARS AGO TEN THOUSAND MEN SHED THEIR\n",
        "wavs/49.wav|SIDE IN THE EARLY MORNING HOURS THE TWO BROTHERS STOOD TOGETHER ON THE DECK OF THE U S S HINRICE\n",
        "wavs/50.wav|EFOREBOARDING TWO SEPARATE HIGGINS LANDING CRAFT IF I DON'T MAKE IT BILL SAID PLEASE PLEASE TAKE CARE OF MY\n",
        "wavs/51.wav|FAMILY RAY ASKED HIS BROTHER TO DO THE SAME OF THE THIRTY ONE MEN ONE RAISED LANDING CRAFT ONLY RAY AND SIX\n",
        "wavs/52.wav|LAZERS MADED TO THE BEACH THERE WERE ONLY A FEW OF THEM LEFT THEY CAME TO THE SECTRE RIGHT HERE BELOW US\n",
        "wavs/53.wav|EASY RED IT WAS CALLED AGAIN AND AGAIN RAY RAN BACK INTO THE WATER HE DRAGGED OUT ONE MAN AFTER ANOTHER\n",
        "wavs/54.wav|HE WAS SHOT THROUGH THE ARM HIS LEG WAS RIPPED OPEN BY SHRAPNEL HIS BACK WAS BROKEN\n",
        "wavs/55.wav|HE NEARLY DROWNED HE HAD BEEN ON THE BEACH FOR HOURS BLEEDING AND SAVING LIVES WHEN HE FINALLY LOST CONSCIOUSNESS\n",
        "wavs/56.wav|HE WOKE UP THE NEXT DAY ON A COT BESIDE ANOTHER BADLY WOUNDED SOLDIER HE LOOKED OVER AND SAW HIS BROTHER BILL HE\n",
        "wavs/57.wav|BLOOD AND THOUSANDS SACRIFICED THEIR LIVES FOR THEIR BROTHERS FOR THEIR COUNTRIES AND FOR THE SURVIVAL OF LIBERTY\n",
        "wavs/58.wav|RELENTING FIRE FROM THESE BLUFFS KEPT THE AMERICANS PINNED DOWN ON THE SAND NOW RED WITH OUR HERO'S BLOOD THEN JUST A FEW HUNDRED YARDS FOM WERHAM'S\n",
        "wavs/59.wav|DENDING A BREAK THROUGH CAME THE BATTLE TURNED AND WITH IT HISTORY DOWN ON THE BEACH CAPTAIN\n",
        "wavs/60.wav|JOE DARSON THE SON OF A TEXAS PREACHER LED COMPANY G THROUGH A MINE FIELD TO A NATURAL FALD IN THE HILL\n",
        "wavs/61.wav|SIDE STILL HERE JUST BEYOND THIS PATH TO MY RIGHT CAPTAIN DARSON SNUCK BENEATH AN ENEMY MACHINE GUN PERCH AND TOSSED HIS GRENADES\n",
        "wavs/62.wav|TO DAY WE REMEMBER THOSE WHO FELL AND WE HONOUR ALL WHO FOUGHT RIGHT HERE IN NORMANDY THEY WON BACK\n",
        "wavs/63.wav|SOON AMERICAN TROOPS WERE CHARGING UP DARSAN'S DRAW WHAT A JOB HE DID WHAT BRAVERY HE SHOWED\n",
        "wavs/64.wav|LIEUTENANT SPALDING AND THE MEN FROM COMPANY E MOVED ON TO CRUSH THE ENEMY'S STRONG POINT ON THE FAR SIDE OF THIS CEMETERY AND STOP THE S\n",
        "wavs/65.wav|ATER ON THE BEACH BELOW COUNTLESS MOOR AMERICANS POURED OUT ACROSS THIS GROUND ALL OVER THE COUNTRYSIDE THEY JOINED FELL\n",
        "wavs/66.wav|TO RETURN HE SAID I'M GOING TO RETURN SIX DAYS AFTER D DAY HE REJOINED HIS COMPANY TWO THIRDS HAD BEEN KI\n",
        "wavs/67.wav|DFORD VIRGINIA ALONE BEFORE LONG A GRENADE LEFT PRIVATE PICKET AND HE WAS GRAVELY WOUNDED\n",
        "wavs/68.wav|SO BADLY WON'T IT AGAIN HE CHOSE TO RETURN HE DIDN'T CARE HE HAD TO BE HERE HE WAS THEN WOUNDED A THIRD TIME AND LAID ON\n",
        "wavs/69.wav|THIS GROUND FOR CIVILIZATION TO MORE THAN ONE HUNDRED AND SEVENTY VETERANS OF THE SECOND WORLD WAR WHO JOIN US TO DAY YOU ARE AMONG\n",
        "wavs/70.wav|CONSCIOUS FOR TWELVE DAYS THEY THOUGHT HE WAS GONE THEY THOUGHT HE HAD NO CHANCE RUSSELL PICKET IS THE LAST KNOWN SURVIVOR OF THE LEGENDER\n",
        "wavs/71.wav|TO LIBERATE JEWS WHO HAD SUFFERED THE BOTTOMLESS HORRORS OF THE HOLLACOST AND SOME WARRIORS FELL ON OTHER FIELDS OF BATTLE RETURNING\n",
        "wavs/72.wav|THE VERY GREATEST AMERICANS WHO WILL EVER LIVE YOU ARE THE PRIDE OF OUR NATION YOU ARE THE GLORY OF OUR REPUBLIC\n",
        "wavs/73.wav|TO REST ON THIS SOIL FOR ETERNITY BEFORE THIS PLACE WAS CONSECRATED TO HISTORY THE LAND WAS OWNED BY A FRENCH FARMER\n",
        "wavs/74.wav|A MEMBER OF THE FRENCH RESISTANCE THESE WERE THE GREAT PEOPLE THESE WERE STRONG AND TOUGH PEOPLE HIS TERRIFIED WIFE\n",
        "wavs/75.wav|MERICAN HE SAID I'M HERE TO HELL THE FRENCHWOMAN WAS OVERCOME WITH EMOTION AND CRIED DAYS LATER SHE LAID FLOWERS ON FRESH AMER\n",
        "wavs/76.wav|THANK YOU TLAS VERY MUCH IT'S A PRIVILEGE TO BE HERE AT THE SFORM WHERE LEADERS IN BUSINESS SCIENCE ART DIPLOMACY AND WORLD AFFAIRS HAVE GATHERED FOR MANY MANY YEARS TO\n",
        "wavs/77.wav|PEOPLE WE HAD DINNER LAST NIGHT WITH ABOUT FIFTEEN LEADERS OF INDUSTRY NONE OF WHOM I KNEW BUT ALL OF WHOM I'VE READ ABOUT FOR YEARS AND IT WAS TRULY AN INCREDIBL\n",
        "wavs/78.wav|GROUP AND I THINK I HAVE FIFTEEN NEW FRIENDS SO THIS HAS BEEN REALLY GREAT WHAT YOU'VE DONE IN PUTTING IT TOGETHER THE ECONOMIC FORUM THE TAX REFORM WAS A DREAM\n",
        "wavs/79.wav|OF LOT OF A LOT OF PEOPLE OVER MANY YEARS BUT THEY WERE UNTABLE TO GET IT DONE MANY PEOPLE TRIED AND RONALD RAGERD WAS REALLY THE LAST TO MAKE A MEANINGFUL CUT AND REFORM AND OURS IS CUTTING AND REFORM\n",
        "wavs/80.wav|MING WE EMPHASIZE CUTT BUT THE REFORM IS PROBABLY ALMOST AS IMPORTANT WE'VE WANTED TO DO IT IT IS VERY TOUGH POLITICALLY TO DO IT HARD TO BELIEVE THAT WOULD BE\n",
        "wavs/81.wav|T IT IS VERY VERY TOUGH THAT'S WHY IT HASN'T BEEN DONE IN CLOSE TO FORTY YEARS AND ONCE WE GOT IT GOING IT WAS GOING AND THE BIG AND I WOULDN'T SAY A TOTAL SURPRISE BUT ONE OF TH\n",
        "wavs/82.wav|BIG THINGS THAT HAPPENED AND TOOK PLACE IS EIGHTY AND T AND SOME OTHERS CAME OUT VERY EARLY AND THEY SAID THEY WERE GOING TO PAY THOUSANDS AND THOUSANDS OF DOLLARS TO\n",
        "wavs/83.wav|NEW ON EMPLOYMENT CLAIMS ARE NEAR THE LOWEST WE'VE SEEN IN ALMOST HALF A CENTURY AFRICAN AMERICAN UNEMPLOYMENT HAS REACHED THE LOWEST RATE EVER RECORDED\n",
        "wavs/84.wav|PEOPLE THAT WORK FOR THEIR COMPANIES AND YOU HAVE THREE HUNDRED THOUSAND FOUR HUNDRED THOUSAND FIVE HUNDRED THOUSAND PEOPLE WORKING FOR THESE COMPANIES AND ALL OF A SUDDEN IT BECAME LIKE A BIG WATERFALL A BIG BEAUTIFUL WATERFALL\n",
        "wavs/85.wav|WHERE SO MANY COMPANIES ARE DOING IT AND EVEN TO DAY THEY JUST ANNOUNCED MANY MORE BUT EVERY DAY THEY ANNOUNCE MORE AND MORE AND NOW IT'S A FIGHT FOR WHO'S GOING TO GIVE THE MOST ITS STARTED AT A THOUSAND NOW WE HAVE EM UP TO THREETH\n",
        "wavs/86.wav|HOUSAND THIS IS SOMETHING THAT WE DIDN'T ANTICIPATE OFTENTIMES IN BUSINESS THINGS HAPPEN THAT YOU DON'T ANTICIPATE USUALLY THAT'S A BAD THING BUT THIS WAS A GOOD THING THIS\n",
        "wavs/87.wav|CAME OUT OF NOWHERE NOBODY EVER THOUGHT OF THIS AS A POSSIBILITY EVEN WE IT WASN'T IN THE EQUATION WE WAITED WE SAID WHADLE FEBRUARY FIRST WHEN THE CHECKS START COMING IN AND PE\n",
        "wavs/88.wav|LCLAUS HAVE A LOT MORE MONEY ON THEIR PAY CHACK CAUSE IT'S NOT JUST A LITTLE MONEY THERE'S A LOT OF MONEY FOR PEOPLE MAKING A LIVING DOING WHATEVER THEY MAY BE DOING AND WE REALLY THOUGHT FEBRUARY FIRST IT WAS GOING TO K\n",
        "wavs/89.wav|CK IN AND EVERYBODY WAS GOING TO BE WOE WE HAVEN'T EVEN GOTTEN THERE YET AND IT'S KICKED IN AND IT'S HAD A INCREDIBLE IMPACT ON THE STOCK MARKET AND THE STOCK PRICES WE'VE SAID EIGHTY FOUR RECORDS\n",
        "wavs/90.wav|SINCE MY ELECTION RECORD STOCK MARKET PRICES MEANING WE HIT NEW HIVES EIGHTY FOUR DIFFERENT TIMES OUT OF A ONE YEAR PERIOD AND THAT'S A GREA\n",
        "wavs/91.wav|THING AND INOR FAIRNESS THAT WAS DONE BEFORE WE PASSED THE TAXI CUTS AND TAX REFORM SO WHAT HAPPENED IS REALLY SOMETHING SPECIAL THEN AS YOU KNOW AND AS I JUST SAID\n",
        "wavs/92.wav|APPLE CAME IN WITH THREE HUNDRED AND FIFTY BILLION DOLLARS AND I TELL YOU AI SPOKE WITH TIM COOK I SAID TIM I WILL NEVER CONSIDER THIS WHOLE GREAT RUN THAT WE'VE MADE\n",
        "wavs/93.wav|COMPLETE UNTIL YOU START BUILDING PLANTS IN THE U S AND I WILL TELL YOU THIS MOVED UP VERY SUBSTANTIALLY BUT WHEN I HEARD THREE HUNDRED AND FIFTY I THOUGHT HE WAS TALKING I THOUGHT THEY WERE TALKI\n",
        "wavs/94.wav|DISCUSS HOW WE COULD ADVANCE PROSPERITY SECURITY AND PEACE I AM HERE TO DAY TO REPRESENT THE INTERESTS OF THE AMERICAN PEOPLE AND TO AFFIRM AMERICA'S FRIENDSHIP AND PARTNERSHI\n",
        "wavs/95.wav|IN THE UNITED STATES AND SO HAS UNEMPLOYMENT AMONG HIS SPANIC AMERICANS THE WORLD IS WITNESSING THE RESURGENCE OF A STRONG\n",
        "wavs/96.wav|THREE HUNDRED FIFTY MILLION DOLLARS AND BY THE WAY THAT'S A NICE SIZED PLANT NOT THE GREATEST BUT NOT BAD AND THEY SAID NO SIR IT'S THREE HUNDRED FIFTY MILLION DOLLAR\n",
        "wavs/97.wav|I SAID THAT IS SOMETHING WELL WE HAVE TREMENDOUS AMOUNTS OF MONEY AND POLLUDING MY NEW FOUND FRIENDS FROM LAST NIGHT A GREAT COMPANIES THEY ARE ALL INVESTING ER WHEN ONE OF THE GE\n",
        "wavs/98.wav|LEMEN SAID HE'S PUTTING IN TWO BILLION DOLLARS BECAUSE OF THE TAX CUTS I SAID TO MYSELF WOW HE'S ACTUALLY THE CHEAP ONE IN THE GROUP BECAUSE THEY'RE PUTTING IN MASSIVE NUMBERS OF BILLIONS OF DOLLARS SO\n",
        "wavs/99.wav|I THINK YOU HAVE A BRAND NEW UNITED STATES YOU HAVE A UNITED STATES WHERE PEOPLE FROM ALL OVER THE WORLD ARE LOOKING TO COME AND AND INVEST AND THERE'S JUST NOTHING\n",
        "wavs/100.wav|LIKE WHAT'S HAPPENING AND I JUST WANT TO FINISH BY I HAVE A A GROUP OF PEOPLE THAT HAVE BEEN SO OUT SO HAVE A WHOLE LOT OF EM SO I WON'T INTRODUCE CUS AND I'LL INSULT AT LEAST HALF OF EM BUT I'VE HAD A GROUP OF PEOPLE\n",
        "wavs/101.wav|WORK SO HARD ON THIS AND OTHER THINGS AND WE'RE REALLY DOING WE HAT A GREAT FIRST YEAR SO SUCCESSFUL IN SO MANY DIFFERENT WAYS AND THERE'S A TREMENDOUS SPIRIT WHEN YOU LOOK AT\n",
        "wavs/102.wav|ALL OF THE DIFFERENT CHARTS AND POLES AND YOU SEE A AS AN EXAMPLE AFRICAN AMERICAN ON EMPLOYMENT AT THE HISTORIC LOW THAT'S NEVER T'S NEVER HAD A PERIOD OF TIME LIKE THIS\n",
        "wavs/103.wav|A SAME WITH HISPANIC WOMEN AT A SEVENTEEN YEAR LOW IT'S IR IT'S VERY HEARTWARMING TO SEE BUT THERE'S A TREMENDOUS SPIRIT IN THE UNITED STATES I WOULD SAY IT'S A SPIRIT LIKE\n",
        "wavs/104.wav|I HAVE NEVER WITNESSED BEFORE I'VE BEEN HERE FOR A WHILE I HAVE NEVER WITNESSED THE SPIRIT THAT OUR COUNTRY HAS RIGHT NOW SO I JUST WANT TO THANK YOU ALL AND ALL OF THOSE THAT ARE POURING\n",
        "wavs/105.wav|BILLIONS OF DOLLARS INTO OUR COUNTRY OR TEN DOLLARS INTO OUR COUNTRY WE THANK YOU VERY MUCH THANK YOU MISS E BESEDAND I WILL I WILL ASK YOU MAYBE ERPERSONAL QUESTION THEREBOUT\n",
        "wavs/106.wav|AND PROSPEROUS AMERICA I AM HERE TO DELIVER A SIMPLE MESSAGE THERE HAS NEVER BEEN A BETTER TIME TO HIRE TO BUILD TO INVEST AND TO GROW IN THE UNITED STATES\n",
        "wavs/107.wav|BEFORE DOING SO IT STOUNDS VERY UNTEERESTING A CONOLETY I DIDN'T KNOW ABOUT THIS ONE I WOULD LIKE TO ACKNOWLEDGE THE STRONG MAAM THE PESENCE OF E YOUR CAPINGTEM MBOSIES WHO\n",
        "wavs/108.wav|E TREMENDOUSLY CONTRIBUTED TO TE DISCUSSIONS OR GOOD IT'S THE LAST I WOULD LIKE TO DO THAT THAT'S VERY WELL NOW STEPHEN WILBUR GARRY\n",
        "wavs/109.wav|ROBERT EVEN MY GENERAL AND MY VARIOUS OTHER GENERALS YOU KNOW WE'RE MAKING OUR MILITARY PROTECTION A LITTLE BIT BETTER FOR US TOO SO THANK YOU VERY MUCH\n",
        "wavs/110.wav|S EVERYBODY UNDERSTAND THAT I THINK SO THANK YOU ALL FOR BEING I'LL MY MY L MAYBE HERSON A QUESTION WOULD BE AM WHAT EXPERIENCE FROM YOUR\n",
        "wavs/111.wav|PAST HAVE BEEN MOST USEFUL IN PRIPALING YOU FOR SEPRESIDENCY WELL BEING A BUSINESS MAN HAS BEEN A GREAT EXPERIENCE FOR ME I\n",
        "wavs/112.wav|'VE LOVED IT I'VE ALWAYS LOVED BUSINESS I'VE ALWAYS BEEN GOOD AT BUILDING THINGS AND I'VE ALWAYS BEEN VERY SUCCESSFUL AT MAKING MONEY I'D BUISED THINGS THAT WOULD FAIL THAT WOULD BE FAILURES AND I TURN EM AROUND AND TRY AND\n",
        "wavs/113.wav|ET EM FOR THE RIGHT PRICE AND THEN I TURN IM ROUND MAKE EM SUCCESSFUL AND I'VE BEEN GOOD AT IT AND THAT TAKES A CERTAIN ABILITY AND YOU KNOW HISTORICALLY I GUESS THERE'S NEVER REALLY BEEN A BUSINESS MAN OR BUSINESS PERSON\n",
        "wavs/114.wav|A ELECTED PRESENT'S ALWAYS BEEN A GENERAL OR A POLITICIAN THROUGHOUT HISTORY IT'S ALWAYS BEEN A GENERAL YOU HAE TO BE A GENERAL BUT MOSTLY IT WAS POLITICIANS YOU'D NEVER HAVE A BUSINESS MAN AND\n",
        "wavs/115.wav|IN ALL FAIRNESS I WAS SAYING TO TLAUS LAST NIGHT HAD THE OPPOSING PARTY TO ME ONE SOME OF WHOM YOU BACKED SOME OF THE PEOPLE IN THE ROOM INSTEAD OF BEING\n",
        "wavs/116.wav|UP ALMOST FIFTY PER CENT THE STOCK MARKET IS UP SINCE MY ELECTION ALMOST FIFTY PER CENT RATHER THAN THAT I BELIEVE THE STOCK MARKET FROM THAT LEVEL THE INITIAL LEVEL WOULD HAVE BEEN DOWNFLO\n",
        "wavs/117.wav|S AMERICA IS OPEN FOR BUSINESS AND WE ARE COMPETITIVE ONCE AGAIN THE AMERICAN ECONOMY IS BY FAR THE LARGEST IN THE WORLD A\n",
        "wavs/118.wav|S TO FIFTY PER CENT THAT'S WHERE WE WERE HEADING I REALLY BELIEVE THAT BECAUSE THEY WEREGING TO PUT ON MASSIVE NEW REGULATIONS YOU COULDN'T BREATHE IT WAS CHOKING OUR COUNTRY TO DEATH AND I WAS ABLE TO SEE THAT GLAUSE AS A BUSINESS PURSE\n",
        "wavs/119.wav|AND THE OTHER THING IS I'VE ALWAYS SEEMED TO GET FOR WHATEVER REASON A DISPROPORTIONATE AMOUNT OF PRESS OR MEDIA AND THROUGHOUT MY WHOLE LIFE SOMEBODY WILL EXPLAIN\n",
        "wavs/120.wav|SOME DAY WHY BUT I'VE ALWAYS GOTTEN A LA AND AS A BUSINESS MAN I WAS ALWAYS TREATED REALLY WELL BY THE PRESS YOU KNOW THE NUMBERS SPEAK AND THINGS HAPPEN BUT I'VE ALWAYS REALLY HAD A VERY GOOD PRESS AND IT WASN'T TILL\n",
        "wavs/121.wav|I BECAME A POLITICIAN THAT I REALIZED HOW NASTY HOW MEAN HOWA VICIOUS AND HOW FAKE THE PRESS CAN BE AS THE CAMERA START GOING OFF IN THE BACK\n",
        "wavs/122.wav|BUT BUT OVER ALL I MEAN THE BOTTOM LINE SOMEBODY SAID WELL THEY COULDN'T HAVE BEEN THAT BED BECAUSE HERE WE ARE WE'RE PRECEDENT AND I THINK WE'RE DOING A REALLY GREAT JOB WITH MY TEAM I HAVE A TEAM OF JUS\n",
        "wavs/123.wav|TREMENDOUS PEOPLE AND I THINK WE'RE DOING A VERY SPECIAL JOB AND I REALLY BELIEVE IT WAS TIME AND WAS TIME TO DO THAT JOB BECAUSE I DON'T THINK THE UNITED STATES WOUL\n",
        "wavs/124.wav|HAV DONE VERY WELL IF IT WENT THROUGH FOUR OR EIGHT MORE YEARS OF REGULATION AND REALLY A VERY ANTI BUSINESS GROUP OF PEOPLE WE HAVE A VERY PRO BUSINESS GROUP WE\n",
        "wavs/125.wav|HAVE A REGULATIONS CUT TO A LEVEL IN THE HISTORY OF OUR COUNTRY CLASS THIS WAS REPORTED RECENTLY IN ONE YEAR WE'VE CUT MORE REGULATIONS IN MY ADMINISTRATION THAN ANY\n",
        "wavs/126.wav|ETHER ADMINISTRATION IN FOUR EIGHT OR SIXTEEN YEARS IN THE ONE CASE WE'VE GUT MORE REGULATIONS IN ONE YEAR AND WE HAVE AWAYS TO GO I WE'RE PROBABLY FIFTY PER CENT DONE AND WE'RE GOING TO HAVE\n",
        "wavs/127.wav|E REGULATION THERE'S NOTHING WRONG WITH RULES AND REGULATIONS YOU NEED EM BUT WE'VE CUT MORE THAN ANY ADMINISTRATION EVER IN THE HISTORY OF OUR COUNTRY AND WE\n",
        "wavs/128.wav|D WE'VE JUST ENACTED THE MOST SIGNIFICANT TAX CUTS AND REFORM IN AMERICAN HISTORY WE'VE MASSIVELY CUT TAXES FOR THE MIDDLE CLASS AND SMALL BUSINESS IS TO LET\n",
        "wavs/129.wav|STILL HAVE AWAGE TO GO SO I THINK BETWEEN THAT AND THE TREMENDOUS TAX CUTS WE'VE REALLY DONE SOMETHING AND ONE OTHER THING I SAID OI I SAW IT LAST NIGHT WITH SOME OF THE LEADERS AND THE BUSINESS PEOPLE\n",
        "wavs/130.wav|I THINK I'VE BEEN A CHEER LEADER FOR A COUNTRY AND EVERYBODY REPRESENTING A COMPANY OR A COUNTRY HAS TO BE A CHEER LEADER OR NO MATTER WHAT YOU DO IT'S JUST NOT GOING TO WORK\n",
        "wavs/131.wav|AND THE REASON I MACHEER LEADER IS BECAUSE IT'S EASY BECAUSE I LOVE OUR COUNTRY AND I THINK WE'RE JUST DOING REALLY WELL AND WE LOOK FORWARD TO SEEING YOU IN AMERICA\n",
        "wavs/132.wav|SPECIAL PLACE AND WHERE YOU ARE IS A SPECIAL PLACE ALSO THANK YOU ALL VERY MUCH I APPRECIATED THANK YOU THANK YOU VERY MUCH EH\n",
        "wavs/133.wav|THE PRESIDENT FOR BEING WITH US SEWOTH ECONOMIC FORM COMMUNITY WHO IS ASSEMBLED HERE WILL BE CERTAINLY AND I QUOTE YOU FROM THE LAST PIECE OF\n",
        "wavs/134.wav|YOUR REMARKS WILL BE CERDENLY BE AMONGST A HARD WORKING MEN AND WOMEN WHO DO SO DUTY EACH AND EVERY DAY MAKINGS THIS WORLD\n",
        "wavs/135.wav|BETTER PLACE FOR EVERYONE THANK YOU VERY MUCH THANK YOU FOR THANK YOU VERY MUCH EVERYBODY THANK YOU\n",
        "wavs/137.wav|WORKING FAMILIES KEEP MORE OF THEIR HARD EARNED MONEY WE LOWERED OUR CORPORAL TAXERATE FROM THIRTY FIVE PER CENT ALL THE WAY DOWN TO TWENTY ONE PER CENT\n",
        "wavs/138.wav|AS A RESULT MILLIONS OF WORKERS HAVE RECEIVED TAX CUT BONASSES FROM THEIR EMPLOYERS IT AMOUNTS AS LARGE AS THREE THOUSAND DOLLARS THE TAX CU\n",
        "wavs/139.wav|BILL IS EXPECTED TO RAISE THE AVERAGE AMERICANS HOUSEHOLD INCOME BY MORE THAN FOUR THOUSAND DOLLARS THE WORLD'S LARGEST COMPANY APPLE ANNOUNCED AT PLANS TO BRING TWO HUNDRE\n",
        "wavs/140.wav|AND FORTY FIVE BILLION DOLLARS IN OVERSEAS PROFITS HOME TO AMERICA THEIR TOTAL INVESTMENT INTO THE UNITED STATES ECONOMY WILL BE MORE THAN THREE HUNDRED AND FIFT\n",
        "wavs/141.wav|Y BILLION DOLLARS OVER THE NEXT FIVE YEARS NOW IS THE PERFECT TIME TO BRING YOUR BUSINESS YOUR JOBS AND YOUR INVESTMENTS TO THE UNITED STATES THI\n",
        "wavs/142.wav|IS ESPECIALLY TRUE BECAUSE WE HAVE UNDERTAKEN THE MOST EXTENSIVE REGULATORY REDUCTION EVER CONCEIVED REGULATION IS\n",
        "wavs/143.wav|IN BUILDING A BETTER WORLD LIKE ALL NATIONS REPRESENTED AT THIS GREAT FORUM AMERICA HOPES FOR A FUTURE IN WHICH EVERY ONE CAN PROSPER\n",
        "wavs/144.wav|DEALFH TAXATION THE U S LIKE MANY OTHER COUNTRIES UNELECTED BUROCRATS AND WE HAVE BELIEVE ME WE HAVE THEM ALL OVER THE PLACE\n",
        "wavs/145.wav|AND THEY'VE IMPOSED CRUSHING AND ANTI BUSINESS AND ANTI WORKER REGULATIONS ON OUR CITIZENS WITH NO VOTE NO LEGISLATIVE DEBATE AND NO REAL ACCOUNT OF\n",
        "wavs/146.wav|LITY IN AMERICA THOSE DAYS ARE OVER I PLEDGED TO ELIMINATE TWO UNNECESSARY REGULATIONS FOR EVERY ONE NEW REGULATION\n",
        "wavs/147.wav|WE HAVE SUCCEEDED BEYOND OUR HIGHEST EXPECTATIONS INSTEAD OF TWO FOR ONE WE HAVE CUT TWENTY TWO BURDENSOME REGULATIONS\n",
        "wavs/148.wav|FOR EVERY ONE NEW RULE WE ARE FREEING OUR BUSINESSES AND WORKERS SO THEY CAN THRIVE AND FLOURISH AS NEVER BEFORE WE ARE CREATING AN ENVIRONME\n",
        "wavs/149.wav|THAT ATTRACTS CAPITAL INVITES INVESTMENT AND REWARDS PRODUCTION AMERICA IS THE PLACE TO DO BUSINESS SO COME TO AMERICA WHERE YOU CAN\n",
        "wavs/150.wav|INNOVATE CREATE AND BUILD I BELIEVE IN AMERICA AS PRESIDENT OF THE UNITED STATES I WILL ALWAYS PUT AMERICA FIRST\n",
        "wavs/151.wav|JUST LIKE THE LEADERS OF OTHER COUNTRIES SHOULD PUT THEIR COUNTRY FIRST ALSO WBUT AMERICA FIRST DOES NOT MEAN\n",
        "wavs/152.wav|AMERICA ALONE WHEN THE UNITED STATES GROWS SO DOES THE WORLD AMERICAN PROSPERITY HAS CREATED COUNTLESS JOBS ALL AROUND THE GLOW\n",
        "wavs/153.wav|AND THE DRIVE FOR EXCELLENCE CREATIVITY AN INNOVATION IN THE U S HAS LED TO IMPORTANT DISCOVERIES THAT HELP PEOPLE EVERYWHERE LIVE MORE PROSPEROUS AND FAR\n",
        "wavs/154.wav|AND EVERY CHILD CAN GROW UP FREE FROM VIOLENCE POVERTY AND FEAR OVER THE PAST YEAR WE HAVE MADE EXTRAORDINARY STRIDES IN THE U S WHERE\n",
        "wavs/155.wav|R HEALTHIER LIVES AS THE UNITED STATES PURSUES DOMESTIC REFORMS TO UNLEASE JOBS AND GROWTH WE ARE ALSO WORKING TO REFORM THE INTERNATIONAL\n",
        "wavs/156.wav|RATING SYSTEM SO THAT IT PROMOTES BROADLY SHARED PROSPERITY AND REWARDS TO THOSE WHO PLAY BY THE RULES WE CANNOT HAVE FREE AND A\n",
        "wavs/157.wav|IN TRADE IF SOME COUNTRIES EXPLOIT THE SYSTEM AT THE EXPENSE OF OTHERS WE SUPPORT FREE TRADE BUT IT NEEDS TO BE FAIR\n",
        "wavs/158.wav|AND IT NEEDS TO BE RECIPROCAL BECAUSE IN THE END UNFAIR TRADE UNDERMINES US ALL THE UNITED STATES WILL NO LONGER TURN A BLIND EYE TO ON\n",
        "wavs/159.wav|FAR ECONOMIC PRACTICES INCLUDING MASSIVE INTELLECTUAL PROPERTY THEFT INDUSTRIAL SUBSIDIES AND PERVASIVE STATE LED ECONOMIC PLANNING\n",
        "wavs/160.wav|THESE AND OTHER PREDATORY BEHAVIORS ARE DISTORTING THE LOBAL MARKETS AND HARMING BUSINESSES AND WORKERS NOT JUST IN THE U S BUT AROUND THE GLUV\n",
        "wavs/161.wav|JUST LIKE WE EXPECT THE LEADERS OF OTHER COUNTRIES TO PROTECT THEIR INTERESTS AS PRESIDENT OF THE UNITED STATES I WILL ALWAYS PROTECT THE INTERESTS OF OUR COUNTRY OUR\n",
        "wavs/162.wav|COMPANIES AND OUR WORKERS WE WILL ENFORCE OUR TRADE LAWS AND RESTORE INTEGRITY TO OUR TRADING SYSTEM ONLY BY INSISTING ON FAIR AND RECIPROCAL\n",
        "wavs/163.wav|TRADE CAN WE CREATE A SYSTEM THAT WORKS NOT JUST FOR THE U S BUT FOR ALL NATIONS AS I HAVE SAID THE UNITED STATES IS PREPARED TO NEGOTIATE\n",
        "wavs/164.wav|MUTUALLY BENEFICIAL BY LATERAL TRADE AGREEMENTS WITH ALL COUNTRIES THIS WILL INCLUDE THE COUNTRIES IN T P P WHICH ARE VERY IMPORTANT W\n",
        "wavs/165.wav|LIFTING UP FORGOTTEN COMMUNITIES CREATING EXCITING NEW OPPORTUNITIES AND HELPING EVERY AMERICAN FIND THEIR PATH TO THE AMERICAN DREAM THE DREAM OF A GREAT JOB A SAFE HO\n",
        "wavs/166.wav|E HAVE AGREEMENTS WITH SEVERAL OF THEM ALREADY WE WOULD CONSIDER NEGOTIATING WITH THE REST EITHER INDIVIDUALLY OR PERHAPS AS A GROUP IF IT IS IN THE INTERESTS OF\n",
        "wavs/167.wav|ALL MY ADMINISTRATION IS ALSO TAKING SWIFT ACTION IN OTHER WAYS TO RESTORE AMERICAN CONFIDENCE AND INDEPENDENCE WE ARE LIF\n",
        "wavs/168.wav|TING SELF IMPOSED RESTRICTIONS ON ENERGY PRODUCTION TO PROVIDE A FORDABLE POWER TO OUR CITIZENS AND BUSINESSES AND TO PROMOTE ENERGY SECURITY FOR OUR FRIEN\n",
        "wavs/169.wav|S ALL AROUND THE WORLD NO COUNTRY SHOULD BE HELD HOSTAGE TO A SINGLE PROVIDER OF ENERGY AMERICA IS ROARING BACK AND NOW IS THE T\n",
        "wavs/170.wav|ME TO INVEST IN THE FUTURE OF AMERICA WE HAVE DRAMATICALLY CUT TAXES TO MAKE AMERICA COMPETITOR WE ARE ELIMINATING BURDENSOME REGULATIONS AT A RECORD PAY\n",
        "wavs/171.wav|S WE ARE REFORMING THE BUREOCRASY TO MAKE IT LEAN RESPONSIVE AND ACCOUNTABLE AND WE ARE ENSURING OUR LAWS ARE ENFORCED FAIRLY\n",
        "wavs/172.wav|WE HAVE THE BEST COLLEGES AND UNIVERSITIES IN THE WORLD AND WE HAVE THE BEST WORKERS IN THE WORLD ENERGY IS ABUNDANT AND AFFORDABLE THERE HAS NEVER BEEN A BETTER TIME TO DO BUSINESS\n",
        "wavs/173.wav|IN AMERICA WE ARE ALSO MAKING HISTORIC INVESTMENTS IN THE AMERICAN MILITARY BECAUSE WE COULD NOT HAVE PROSPERITY WITHOUT SECURITY TO MAKE THE WORLD SAFER\n",
        "wavs/174.wav|FROM ROGUE REGIMES TERRORISM AND REVISIONISTS POWERS WE ARE ASKING OUR FRIENDS AND ALLIES TO INVEST IN THEIR OWN DEFENCES AND TO MEET THEIR FINANCIAL OBLIG\n",
        "wavs/175.wav|ATIONS OUR COMMON SECURITY REQUIRES EVERY ONE TO CONTRIBUTE THEIR FAIR SHARE MY ADMINISTRATION IS PROUD TO HAVE LED HISTORIC EFFORTS AT THE UNITED NATIONS\n",
        "wavs/176.wav|M AND A BETTER LIFE FOR THEIR CHILDREN AFTER YEARS OF STAGNATION THE UNITED STATES IS ONCE AGAIN EXPERIENCING STRONG ECONOMIC GROWTH\n",
        "wavs/177.wav|ECURITY COUNCIL AND ALL AROUND THE WORLD TO UNITE ALL CIVILIZED NATIONS IN OUR CAMPAIGN OF MAXIMUM PRESSURE TO DENUK THE KOREAN\n",
        "wavs/178.wav|PENINSULA WE CONTINUE TO CALL ON PARTNERS TO CONFRONT A RAN SUPPORT FOR TERRACE AND BLOCK A RAN'S PATH TO A NEWCLEAR WEAPON WE'RE ALSO WORKING WITHO\n",
        "wavs/179.wav|LIS AND PARTNERS TO DESTROY GEHATTES TERRACED ORGANIZATION SUCH AS ISIS AND VERY SUCCESSFULLY SO THE UNITED STATES IS LEADING A VERY BROAD COALITION TO\n",
        "wavs/180.wav|ENY TERRORS CONTROL OF THEIR TERRITORY AND POPULATIONS TO CUT OFF THEIR FUNDING AND TO DISCREDIT THEIR WICKED IDEOLOGY I AM PLEASED TO REPORT THAT THE COALI\n",
        "wavs/181.wav|TION TO DEFEAT ISIS HAS RETAKEN ALMOST ONE HUNDRED PER CENT OF THE TERRITORY ONCE HELD BY THESE KILLERS IN ERAC AND SYRIA THERE IS STIL\n",
        "wavs/182.wav|LL MORE FIGHTING AND WORK TO BE DONE AND TO CONSOLIDATE OUR GAINS WE ARE COMMITTED TO ENSURING THAT AFGANISTAN NEVER AGAIN\n",
        "wavs/183.wav|BECOMES A SAFE HAVEN FARTERAS WHO WANT TO COMMIT MASS MURDER TO OUR CIVILIAN POPULATIONS I WANT TO THANK THOSE NATIONS REPRESENTED HERE TO DAY THAT HAVE\n",
        "wavs/184.wav|JOINED IN THESE CRUCIAL EFFORTS YOU ARE NOT JUST SECURING YOUR OWN CITIZENS BUT SAVING LIVES AND RESTORING HOPE FOR MILLIONS AND MILLIONS OF PEOPLE\n",
        "wavs/185.wav|WHEN IT COMES TO TERRORISM WE WILL DO WHATEVER IS NECESSARY TO PROTECT OUR NATION WE WILL DEFEND OUR CITIZENS AND OUR BORDERS WE ARE ALSO SECURING OUR IMMI\n",
        "wavs/186.wav|GRATION SYSTEM IS A MATTER OF BOTH NATIONAL AND ECONOMIC SECURITY AMERICA IS A CUTTING EDGE ECONOMY WAT OUR EMIGRATION SYSTEM\n",
        "wavs/187.wav|THE STOCK MARKET IS SMASHING ONE RECORD AFTER ANOTHER AND HAS ADDED MORE THAN SEVEN TRILLION DOLLARS IN NEW WEALTH SINCE MY ELECTION\n",
        "wavs/188.wav|IS STUCK IN THE PAST WE MUST REPLACE OUR CURRENT SYSTEM OF EXTENDED FAMILY CHAIN MIGRATION WITH A MERIT BASE SYSTEM OF ADMISSIONS THAT SELECTS\n",
        "wavs/189.wav|NEW ARRIVALS BASED ON THEIR ABILITY TO CONTRIBUTE TO OUR ECONOMY TO SUPPORT THEMSELVES FINANCIALLY AND TO STRENGTHEN OUR COUNTRY IN REBUILDING AMERICA WE A\n",
        "wavs/190.wav|RE ALSO FULLY COMMITTED TO DEVELOPING OUR WORK FORCE WE ARE LIFTING PEOPLE FROM DEPENDENCE TO INDEPENDENCE BECAUSE WE KNOW THE SINGLE BEST ANTI POVERTY PROGRAMM\n",
        "wavs/191.wav|M IS A VERY SIMPLE AND VERY BEAUTIFUL PECHENK TO BE SUCCESSFUL IT IS NOT ENOUGH TO INVEST IN OUR ECONOMY WE MUST\n",
        "wavs/192.wav|NVEST IN OUR PEOPLE WHEN PEOPLE ARE FORGOTTEN THE WORLD BECOMES FRACTURED ONLY BY HEARING AND RESPONDING TO THE VOICES OF THE FOR\n",
        "wavs/193.wav|GOTTEN CAN WE CREATE A BRIGHT FUTURE THAT IS TRULY SHARED BY ALL THE NATION'S GREATNESS IS MORE THAN THE SUM OF ITS PRODUCTION A NATION'S GREATNESS\n",
        "wavs/194.wav|IS THE SUM OF ITS CITIZENS THE VALUES PRIDE LOVE DEVOTION AND CHARACTER OF THE PEOPLE WHO CALL THAT NATION HOME FROM\n",
        "wavs/195.wav|MY FIRST INTERNATIONAL G SEVENTH SUMMIT TO THE G TWENTY TO THE U N GENERAL ASSEMBLY TO APEC TO THE WORLD TRADE ORGANIZATION AND TODAY AT THE WORLD ECONOMIC\n",
        "wavs/196.wav|FORUM MY ADMINISTRATION HAS NOT ONLY BEEN PRESENT BUT HAS DRIVEN OUR MESSAGE THAT WE ARE ALL STRONGER WHEN FREE SOVEREIGN NATIONS COOPERATE\n",
        "wavs/197.wav|RD SHARED GIRLS AND THEY COOPERATE TOWARD SHARED DREAMS REPRESENTED IN THIS ROOM ARE SOME OF THE REMARKABLE CITIZENS FROM ALL OVER THE WORLD YOU ARE NATH\n",
        "wavs/198.wav|ONSUMER CONFIDENCE BUSINESS CONFIDENCE AND MANUFACTURING CONFIDENCE ARE THE HIGHEST THEY HAVE BEEN IN MANY DECADES SINCE BY ELECTION\n",
        "wavs/199.wav|NAL LEADERS BUSINESS TITANS INDUSTRY GIANTS AND MANY OF THE BRIGHTEST MINES IN MANY FIELDS EACH OF YOU HAS THE POWER TO CHANGE HEARTS\n",
        "wavs/200.wav|TRANSFORM LIVES AND SHAPE YOUR COUNTRY'S DESTINIES WITH THIS POWER COMES AN OBLIGATION HOWEVER A DUTY OF LOYALTY TO THE PEOPLE WORKERS AND CUSTOMERS WHO\n",
        "wavs/201.wav|VE MADE YOU WHO YOU ARE SO TOGETHER LET US RESOLVE TO USE OUR POWER OUR RESOURCES AND OUR VOICES NOT JUST FOR OURSELVES BUT\n",
        "wavs/202.wav|OR OUR PEOPLE TO LIFT THEIR BURDENS TO RAISE THEIR HOPES AND TO EMPOWER THEIR DREAMS TO PROTECT THEIR FAMILIES THEIR COMMUNITIES THEIR HISTORIES AND THEIR FUTURES\n",
        "wavs/203.wav|THAT'S WHAT WE'RE DOING IN AMERICA AND THE RESULTS ARE TOTALLY UNMISTAKABLE IT'S WHY NEW BUSINESSES AND INVESTMENT ARE FLOODING IN IT'S W\n",
        "wavs/204.wav|Y OUR UNEMPLOYMENT RATE IS THE LOWEST IT'S BEEN IN SO MANY DECADES IT'S WHY AMERICA'S FUTURE HAS NEVER BEEN BRIGHTER TO DAY I AM INVITING ALL OF YOU T\n",
        "wavs/205.wav|BECOME PART OF THIS INCREDIBLE FUTURE WE ARE BUILDING TOGETHER THANK YOU TO OUR HOSTS THANK YOU TO THE LEADERS AND INNOVATORS IN THE AUDIENCE BUT MOST IMPORTANTLY THANK YOU TO AL\n",
        "wavs/206.wav|LE OF THE HARD WORKING MEN AND WOMEN WHO DO THEIR DUTY EACH AND EVERY DAY MAKING THIS A BETTER WORLD FOR EVERYONE TOGETHER LET US SEND OUR LOVE\n",
        "wavs/207.wav|AND OUR GRATITUDE TO MAKE THEM BECAUSE THEY REALLY MAKE OUR COUNTRIES RUN THEY MAKE OUR COUNTRIES GREAT THANK YOU\n",
        "wavs/208.wav|AND GOD BLESS YOU ALL THANK YOU VERY MUCH\n",
        "wavs/209.wav|E'VE CREATED TWO POINT FOUR MILLION JOBS AND THAT NUMBER IS GOING UP VERY VERY SUBSTANTIALLY SMALL BUSINESS OPTIMISM IS AT AN OLD TIME HIGH\"\"\"\n",
        "\n",
        "lines = data.strip().split('\\n')\n",
        "files = []\n",
        "# Extract the filename and text part\n",
        "for line in lines:\n",
        "    filename, sentence = line.split('|')\n",
        "    output_filename = filename.replace(\"wavs/\", \"\")\n",
        "    files+=[output_filename]\n",
        "print(files)\n",
        "\n",
        "\n",
        "# Resample function to ensure both audios have the same sample rate (16kHz)\n",
        "def resample_audio(audio, original_sample_rate, target_sample_rate=16000):\n",
        "    if original_sample_rate != target_sample_rate:\n",
        "        transform = torchaudio.transforms.Resample(orig_freq=original_sample_rate, new_freq=target_sample_rate)\n",
        "        audio = transform(audio)\n",
        "    return audio\n",
        "\n",
        "Pesq_scores = []\n",
        "Stoi_scores = []\n",
        "llr_scores = []\n",
        "wss_scores = []\n",
        "snrseg_scores = []\n",
        "csig_scores = []\n",
        "cbak_scores = []\n",
        "covl_scores = []\n",
        "\n",
        "for i in files:\n",
        "    # Load predicted and original audio files\n",
        "    predicted, sample_rate_predicted = torchaudio.load(f\"output_wavs/{i}\")\n",
        "    original, sample_rate_original = torchaudio.load(f\"trump/wavs/{i}\")\n",
        "\n",
        "    # Resample to 16kHz if needed\n",
        "    predicted = resample_audio(predicted, sample_rate_predicted)\n",
        "    original = resample_audio(original, sample_rate_original)\n",
        "\n",
        "    # Convert stereo to mono if necessary\n",
        "    if predicted.shape[0] > 1:\n",
        "        predicted = torch.mean(predicted, dim=0).unsqueeze(0)\n",
        "    if original.shape[0] > 1:\n",
        "        original = torch.mean(original, dim=0).unsqueeze(0)\n",
        "\n",
        "    min_length = min(predicted.shape[1], original.shape[1])\n",
        "    predicted = predicted[:, :min_length]\n",
        "    original = original[:, :min_length]\n",
        "\n",
        "    # Convert tensors to NumPy arrays before calling pysepm functions\n",
        "    predicted_np = predicted.cpu().numpy().squeeze()\n",
        "    original_np = original.cpu().numpy().squeeze()\n",
        "\n",
        "    # PESQ and STOI scores\n",
        "    pesq_score = pesq(predicted, original)\n",
        "    Pesq_scores.append(pesq_score)\n",
        "\n",
        "    stoi_score = stoi(predicted, original)\n",
        "    Stoi_scores.append(stoi_score)\n",
        "\n",
        "    # Compute LLR\n",
        "    llr_score = pysepm.llr(predicted_np, original_np, fs=16000)\n",
        "    llr_scores.append(llr_score)\n",
        "\n",
        "    # Compute WSS\n",
        "    wss_score = pysepm.wss(predicted_np, original_np, fs=16000)\n",
        "    wss_scores.append(wss_score)\n",
        "\n",
        "    # Compute Segmental SNR\n",
        "    snrseg_score = pysepm.SNRseg(predicted_np, original_np, fs=16000)\n",
        "    snrseg_scores.append(snrseg_score)\n",
        "\n",
        "    # Compute CSIG\n",
        "    csig = 3.093 - 1.029 * llr_score + 0.603 * pesq_score - 0.009 * wss_score\n",
        "    csig_scores.append(csig)\n",
        "\n",
        "    # Compute CBAK\n",
        "    cbak = 1.634 + 0.478 * pesq_score - 0.007 * wss_score + 0.063 * snrseg_score\n",
        "    cbak_scores.append(cbak)\n",
        "\n",
        "    # Compute COVL\n",
        "    covl = 1.594 + 0.805 * pesq_score - 0.512 * llr_score - 0.007 * wss_score\n",
        "    covl_scores.append(covl)\n",
        "\n",
        "print(f\"Average PESQ score: {sum(Pesq_scores) / len(Pesq_scores)}\")\n",
        "print(f\"Average STOI score: {sum(Stoi_scores) / len(Stoi_scores)}\")\n",
        "print(f\"Average csig score: {sum(csig_scores) / len(csig_scores)}\")\n",
        "print(f\"Average cbak score: {sum(cbak_scores) / len(cbak_scores)}\")\n",
        "print(f\"Average covl score: {sum(covl_scores) / len(covl_scores)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00efa5d9f50045d68be9e25093a10b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "038d2c3e6c6c4ac18841e2285d047ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "058b42e35ce54197851d63c365fe0048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07165396d1a748c3b7131a0a1f888364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "253aad330715430b998f6b5834a65f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de80c24c48b84bd8907cf9e989ac2875",
              "IPY_MODEL_d2caa1a47ea045979c2764511ab46174",
              "IPY_MODEL_5defe48e0a0d46ce81d3d193e7db5a00"
            ],
            "layout": "IPY_MODEL_d0528afad28b44c6aa38653e29a0cae2"
          }
        },
        "2c881a8147d94c6e8b99782d2c62e535": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ef47add8d8e485d8ba3c3c5e90614ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3047d48b9f1c466a88a209f949870c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38086f2038984ffe8e10a9305796963d",
            "placeholder": "",
            "style": "IPY_MODEL_59782e9550114baca5d1b9c7eca235b4",
            "value": "484M/484M[00:06&lt;00:00,55.4MB/s]"
          }
        },
        "337386121d9c43faa3b739ea7e46eb16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b020e40065412e930b15d6c401483a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37048e5581ef41f88a3ffe95740da732": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31ebd3f6bb64ae78fd79db88d2b960f",
            "placeholder": "",
            "style": "IPY_MODEL_07165396d1a748c3b7131a0a1f888364",
            "value": "vocabulary.txt:100%"
          }
        },
        "38086f2038984ffe8e10a9305796963d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d805355200f47cab3a812e740f90d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b055087a17b4e47a0ff036d76cabeaf",
            "max": 459861,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_805e2d0614a44d9a9644c1e1595783c6",
            "value": 459861
          }
        },
        "4f91d4ee87e34b4eb47d8e80fcca01c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53784e7405cd49b4af158084f1769335": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54685d9ee95e44a5893a2963dc3d0642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59782e9550114baca5d1b9c7eca235b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d6929c3dddd43d983c44a50f2dae798": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8ac4dca5fa445a7ab4af0f2f09e2976",
              "IPY_MODEL_bc4cff7ace414a8cabb6fc2ea78dae3d",
              "IPY_MODEL_c48db4fcdbdc4a83b7eea2e6c62a6951"
            ],
            "layout": "IPY_MODEL_7966ffc105d242e6bc0104327729f459"
          }
        },
        "5defe48e0a0d46ce81d3d193e7db5a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749bf66ebcf0446588aecf241be75f99",
            "placeholder": "",
            "style": "IPY_MODEL_058b42e35ce54197851d63c365fe0048",
            "value": "2.20M/2.20M[00:00&lt;00:00,5.08MB/s]"
          }
        },
        "60b039350cde49e886ced126aee27424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73baabb933df48d4a98420c01dc15c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "749bf66ebcf0446588aecf241be75f99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7966ffc105d242e6bc0104327729f459": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805e2d0614a44d9a9644c1e1595783c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9127cf22ccaf4ebb88e97800b4a99753": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b055087a17b4e47a0ff036d76cabeaf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0afb30114e140868c6a809a80081bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a167fc65d37942908122680edefef1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2dc1d8d365a4db5ab6fcae047e9dd5d",
              "IPY_MODEL_a79d8612254d4f64ae29ea4938a81329",
              "IPY_MODEL_3047d48b9f1c466a88a209f949870c87"
            ],
            "layout": "IPY_MODEL_f26927ea07f04a4d97271629e1ee74e6"
          }
        },
        "a79d8612254d4f64ae29ea4938a81329": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c881a8147d94c6e8b99782d2c62e535",
            "max": 483546902,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b78b55be39f04f21a9f4bddb25bcc343",
            "value": 483546902
          }
        },
        "af015b6c6b01435a99efec64961dadaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78b55be39f04f21a9f4bddb25bcc343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b95b1afac403460181464f1856cb2db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc4cff7ace414a8cabb6fc2ea78dae3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_038d2c3e6c6c4ac18841e2285d047ba5",
            "max": 2370,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00efa5d9f50045d68be9e25093a10b8e",
            "value": 2370
          }
        },
        "c31ebd3f6bb64ae78fd79db88d2b960f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48db4fcdbdc4a83b7eea2e6c62a6951": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f91d4ee87e34b4eb47d8e80fcca01c7",
            "placeholder": "",
            "style": "IPY_MODEL_b95b1afac403460181464f1856cb2db6",
            "value": "2.37k/2.37k[00:00&lt;00:00,41.2kB/s]"
          }
        },
        "d0528afad28b44c6aa38653e29a0cae2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2caa1a47ea045979c2764511ab46174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337386121d9c43faa3b739ea7e46eb16",
            "max": 2203239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73baabb933df48d4a98420c01dc15c0c",
            "value": 2203239
          }
        },
        "d8ac4dca5fa445a7ab4af0f2f09e2976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9127cf22ccaf4ebb88e97800b4a99753",
            "placeholder": "",
            "style": "IPY_MODEL_2ef47add8d8e485d8ba3c3c5e90614ec",
            "value": "config.json:100%"
          }
        },
        "d98833c1238d4abab6c24b8579b9737a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37048e5581ef41f88a3ffe95740da732",
              "IPY_MODEL_4d805355200f47cab3a812e740f90d9a",
              "IPY_MODEL_e2925c315daf4b7488dbc93595923d59"
            ],
            "layout": "IPY_MODEL_a0afb30114e140868c6a809a80081bf4"
          }
        },
        "de80c24c48b84bd8907cf9e989ac2875": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53784e7405cd49b4af158084f1769335",
            "placeholder": "",
            "style": "IPY_MODEL_af015b6c6b01435a99efec64961dadaf",
            "value": "tokenizer.json:100%"
          }
        },
        "e2925c315daf4b7488dbc93595923d59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8952b150684595bfb8d6e6d62a3822",
            "placeholder": "",
            "style": "IPY_MODEL_54685d9ee95e44a5893a2963dc3d0642",
            "value": "460k/460k[00:00&lt;00:00,6.77MB/s]"
          }
        },
        "f26927ea07f04a4d97271629e1ee74e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2dc1d8d365a4db5ab6fcae047e9dd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b020e40065412e930b15d6c401483a",
            "placeholder": "",
            "style": "IPY_MODEL_60b039350cde49e886ced126aee27424",
            "value": "model.bin:100%"
          }
        },
        "fe8952b150684595bfb8d6e6d62a3822": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
